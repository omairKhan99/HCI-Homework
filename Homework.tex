\documentclass[
	%a4paper, % Use A4 paper size
	letterpaper, % Use US letter paper size
]{jdf}

\addbibresource{references.bib}

\author{Omair Tariq Khan}
\email{okhan60@gatech.edu}
\title{Homework 2}

\begin{document}
%\lsstyle

\maketitle
\hfill \break
\hfill \break


\section{Answer to Question 1 - Cooking}
With time, cooking has become an instinctive activity rather than a task that I have to meticulously work through. When I was a beginner, all the details surrounding cooking from recipes, measuring materials, and even the arrangement of the kitchen required constant supervision. I have to admit that I found myself uncertain and hopeless around cooking. But now, as I have come to understand the intricacies of cooking, I am able to enjoy the more creative aspects of it, instead of focusing on negatives of it.

The interface in this scope encompasses, among the many, recipes as the guidelines that provide a more structured approach to combining the ingredients, including measuring mugs, spoons and kitchen scales for precision, and the ingredients along with the cooking implements such as knives, pans and electrical devices which are the basic components of the task. Initially, it took a huge amount of time in recipe interpretation, ingredient measurement, and adjusting the cooking time and temperature. I would read the recipe several times to make sure that I didn't miss anything, look up every term that I did not know, and question my techniques. For instance, chopping vegetables took a lot of time since I wasn't confident with my knife skills. It had been daunting to time dishes to all finish at the same time, and even for simple things, such as boiling pasta, I would commonly use timers. The kitchen itself, where utensils and ingredients were was an interface I had to navigate consciously. 

Now, my thought process while cooking has shifted significantly. Recipes are more of a reference than a strict guide. I have committed so many fundamental techniques to memory-roasting, baking-that I don't need to read the instructions anymore, line by line. The quantities are approximate; I have learned to eyeball it, and I can tell just how much seasonings a dish will take. I am not thinking of components, I am thinking about the meal and what it's going to be like with the flavors and textures combined. Knowing how to set up the kitchen means I don't have to look around for this or that; it's just smooth, and I can enjoy the creativity of cooking rather than fumbling with logistical stuff. All these came with practice and repetition: every time cooking, developing that sense of time, combination, taste, techniques that worked better and mistakes allowed me to make necessary changes or recipes known so that then changing ingredients works very easily. Where I live now, I can also buy the seasoning packet for a particular dish I want to cook from my home country. 

In order to make this interface invisible sooner, I would design a computational system that bridges the gap between beginner and experienced cook. A perfect tool would integrate interactive recipes with real-time guidance. For example, through voice commands, an app may guide users step by step through recipes; at any time, users could stop and ask questions. It allows the user to visually see how to do various techniques, depending on their level. Also, the integration of smart kitchen tools like scales that automatically measure ingredients and sensors observing the cooking process, would reduce cognitive load for a beginner. The application may also give tips based on the user's past cooking history-suggesting seasoning adjustments or flagging common mistakes.

This could help speed up the learning curve by freeing up the user to be more creative with cooking sooner. Less intimidating and intuitive mechanics would make people more confident in experimenting in the kitchen. Of course, practice is key, but an interface designed properly could make those early stages of learning smoother and more pleasant.
\newpage

\section{Answer to Question 2 - Using a smartphone to make video calls }
Making video calls on a smartphone is a task that engages multiple human perceptions, including visual, auditory, and haptic feedback. Each of these types of perception plays a crucial role in ensuring that the user can effectively place and participate in a video call. Visual perception is central to video calls. The screen displays the video picture, allowing users to see the person they are communicating with. It also shows essential interface elements such as buttons to accept or decline a call, mute the microphone, or turn the camera on or off. Notifications for incoming calls or poor connection quality also rely heavily on visual cues. For example, when a call is incoming, the screen typically lights up, displaying the caller's name or number along with an accept and decline button. During a call, visual feedback such as the connection strength indicator or a red border around the screen when recording ensures users are informed about the call’s status.

Auditory perception is equally important. The ringtone is the sound that informs the user that there is an incoming call and the auditory feedback from the caller during the call. Other sounds include the notification tones for new messages, the tones for call being on hold or resumed, and the connection beeps that are typical of dropped audio. These auditory cues are very helpful as they enable the user to know what is happening without having to look at the screen often, thus allowing the user to focus more on the conversation.

Haptic perception is present, but it’s subtler. The ringtone for incoming calls is often accompanied by vibrations, which offer tactile feedback and are useful when auditory cues might be drowned out by noise. Some phones provide a slight vibration when you toggle features like muting the microphone or ending the call. This feedback is useful as it lets the user know that his or her input has been registered without the user having to check visually.

When it comes to these modalities and how to improve feedback through them, I think some new implementations can be explored. For visual perception, a more dynamic interface could include real time emotion detection or control using gesture. For example, the application could highlight the participants in the video feed or with slight hints show who is still to speak so as to enhance communication. For auditory perception spatial audio could be introduced to give a sense of presence in group calls. Voices could be made to appear as if they are coming from different parts of the room depending on where the participants are shown on the video call, which would help with following conversations. Also, personal audio alerts could be used to convey certain information, for example, the battery is almost dead and needs to be plugged in soon. In terms of haptic perception, making the vibration system more interactive could be useful. For example, different vibration patterns could mean different call states; a long vibration for a missed call, or short, repetitive pulses indicating that a call is waiting. Haptics could also be used to indicate gestures. As an example, a quick vibration could confirm a swipe to mute or dismiss a call without requiring the user to glance at the screen.

Outside of these three senses, proprioception, or the sense of body position and movement, could be leveraged for video calls. Smartphones could use gyroscope data to detect how the user is holding the device and adjust the interface accordingly. For instance, tilting the phone could automatically adjust the camera’s orientation or enable gesture-based controls, such as nodding to accept a call or shaking the phone to decline it. These small additions could make video calls more intuitive and engaging, enhancing the overall experience by building on the natural ways humans perceive and interact with their environment. 
\newpage

\section{Answer to Question 3}
\subsection {}

\newpage

\section{Answer to Question 4}


\newpage

\section{References}

\printbibliography[heading=none]
\begin{enumerate}
    \item 
    \item 
    \item 

\end{enumerate}

\end{document}
